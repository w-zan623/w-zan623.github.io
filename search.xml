<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【notes】pytorch学习笔记1-Tensor部分]]></title>
    <url>%2F2019%2F08%2F19%2Fpytorch-1%2F</url>
    <content type="text"><![CDATA[Tensor和autograd 每个深度学习框架的设计核心是张量和计算图，在pytorch里体现为张量系统（Tensor）和自动微分系统（atutograd）。 Tensor 中文译为张量，可以简单看作一个数组。 与numpy里的ndarrays类似，但tensor支持GPU加速。 基础操作接口角度： torch.function tensor.function 存储角度： 不会修改自身数据，如123456789101112131415161718192021222324252627282. 会修改自身数据，如```a.add_(b)```，加法的值储存在a中了。##### 创建Tensor在pytorch中常见的新建tensor的方法：|类别| 特点 | 函数 | 功能 ||:-----|:----|:-----|:-----||第一类：基础方法|最灵活|Tensor(\*sizes)|基础构造函数||第二类：根据sizes建立|常数型|ones(\*sizes)|全1Tensor|||常数型|zeros(\*sizes)|全0Tensor|||常数型|eyes(\*sizes)|对角线为1，其他为0|||概率分布型|rand/randn(\*sizes)|均匀/标准分布||第三类：在一定范围内建立|等差数列型|arange(s,e,step)|从s到e，步长为step|||等差数列型|linspace(s,e,steps)|从s到e，均匀切分成steps份|||概率分布型|normal(mean,std)/uniform(from,to)|正态分布/均匀分布|||概率分布型|randperm(m)|随机分布|* 其中使用Tensor函数新建tensor是最复杂多变的，它既可以接受一个list，并根据list的数据新建tensor，也可根据指定的形状新建tensor，还能传入其他的tensor。```python# 引入必要的包import torch as tfrom torch.autograd import Variable as V 12# 指定tensor的形状a = t.Tensor(2, 3);a tensor([[7.2443e+22, 4.2016e+30, 9.9708e+17], [7.2296e+31, 5.6015e-02, 4.4721e+21]])12# 用list的数据创建tensorb = t.Tensor([[1,2,3],[4,5,6]]);b tensor([[1., 2., 3.], [4., 5., 6.]])1b.tolist(),type(b.tolist()) # 把tensor转为list ([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], list)tensor.size()返回torch.Size()对象，它是tuple的子类，但其使用方式与tuple略有不同。 1b_size = b.size();b_size torch.Size([2, 3])1b.numel() # numelements前五个字母，b中元素总个数，等价于b.nelement() 612345# 创建一个和b形状一样的tensorc = t.Tensor(b_size)# 创建一个元素为2和3的tensord = t.Tensor((2, 3))c, d # 输出结果不同，明显看出torch.Size()对象和tuple的不同 (tensor([[5.8959e-35, 4.5636e-41, 1.0257e-36], [0.0000e+00, 5.0000e+00, 6.0000e+00]]), tensor([2., 3.]))tensor.shape等价于tensor.size() 1c.shape torch.Size([2, 3])* 需要注意：t.Tensor(*sizes)创建tensor时，系统不会马上分配空间，只会计算内存是否够用，使用到tensor时才会分配，而其他方法是创建后会立马分配空间。 * 1t.ones(2, 3) tensor([[1., 1., 1.], [1., 1., 1.]])1t.zeros(2, 3) tensor([[0., 0., 0.], [0., 0., 0.]])1t.linspace(1, 10 ,3) tensor([ 1.0000, 5.5000, 10.0000])1t.randn(2, 3) tensor([[-0.4864, 0.5022, -0.4059], [ 0.4138, 1.1588, -1.1650]])1t.randperm &lt;function _VariableFunctions.randperm&gt;123# 0到n-1随机排列后的数列n = 10t.randperm(n) tensor([2, 5, 8, 3, 4, 1, 0, 7, 9, 6])1t.eye(2, 3) # 不要求行列数一致 tensor([[1., 0., 0.], [0., 1., 0.]])1t.normal(t.Tensor([0]),t.Tensor([1])) tensor([-0.5517])常用Tensor操作 tensor.view方法可以改变tensor的形状，但要保证前后元素总数一致。前后保持数据一致，返回的新tensor与源tensor共享内存。 在实际应用中可能经常需要增加或减少某个维度，这是squeeze和unsqueeze两个函数排上用场。 12a = t.arange(0, 6)a.view(2, 3) tensor([[0, 1, 2], [3, 4, 5]])12b = a.view(-1, 3) # 当某一维为-1时，会自动计算它的大小b tensor([[0, 1, 2], [3, 4, 5]])1b.shape, b.unsqueeze(1).shape # 注意形状，在第1维上增加“1” (torch.Size([2, 3]), torch.Size([2, 1, 3]))1b.unsqueeze(-2) # -2表示倒数第二个维度 tensor([[[0, 1, 2]], [[3, 4, 5]]])12c = b.view(1, 1, 1, 2, 3)c, c.squeeze(0) # 压缩第0维的1 (tensor([[[[[0, 1, 2], [3, 4, 5]]]]]), tensor([[[[0, 1, 2], [3, 4, 5]]]]))1c.squeeze() # 压缩所有的“1”的维度 tensor([[0, 1, 2], [3, 4, 5]])12a[1] = 100b # a和b共享内存，修改了a，b也变了 tensor([[ 0, 100, 2], [ 3, 4, 5]])resize是另一种改变size的方法，和view不同的地方是resize可以改变尺寸，可以有不同数量的元素。如果新尺寸超过了旧尺寸，会自动分配空间，如果新尺寸小于旧尺寸，之前的数据依旧会保存。 12b.resize_(1, 3)b tensor([[ 0, 100, 2]])12b.resize_(3, 3) # 旧的数据依旧被保存，多出的数据会分配新空间。b tensor([[ 0, 100, 2], [ 3, 4, 5], [7881702260482471202, 8319104481852400229, 7075192647680159593]])索引操作Tensor支持和numpy.ndarray类似的索引操作，语法上也类似。 如无特殊说明，索引出来的结果与原tensor共享内存 1a = t.randn(3,4);a tensor([[ 0.8865, -0.8832, -1.0883, -0.2804], [-0.9056, 0.0635, 0.5528, -0.0222], [ 1.4919, -1.0480, -1.7623, 0.8558]])1a[0] # 第0行 tensor([ 0.8865, -0.8832, -1.0883, -0.2804])1a[:, 0] # 第0列 tensor([ 0.8865, -0.9056, 1.4919])1a[0][2] # 第0行第2个元素，等价于a[0,2] tensor(-1.0883)1a[0, -1] # 第0行最后一个元素 tensor(-0.2804)1a[:2] # 前两行 tensor([[ 0.8865, -0.8832, -1.0883, -0.2804], [-0.9056, 0.0635, 0.5528, -0.0222]])1a[:2, 0:2] # 前两行，第0,1列 tensor([[ 0.8865, -0.8832], [-0.9056, 0.0635]])1a[0:1, :2].shape, a[0, :2].shape # 注意两者的区别是形状不同，但是值是一样的 (torch.Size([1, 2]), torch.Size([2]))123a[a &gt; 1] # 等价于a.masked_select(a&gt;1)# 选择结果与原tensor不共享内存空间 tensor([1.4919])1a[t.LongTensor([0,1])] # 第0行和第1行 tensor([[ 0.8865, -0.8832, -1.0883, -0.2804], [-0.9056, 0.0635, 0.5528, -0.0222]])常用的选择函数： 函数 功能 index_select(input, dim, index) 在指定维度dim上选取，例如选取某行某列 masked_select(input, mask) 例子如上，a[a &gt; 0],使用ByteTensor进行选取 non_zero(input) 非0元素的下标 gather(input, dim, index) 根据index，在dim维度上选取数据，输出的size与index一样 gather是一个比较复杂的操作，对于一个二维的tensor，输出的每个元素如下： 12out[i][j] = input[index[i][j]][j] # dim = 0out[i][j] = input[i][index[i][j]] # dim = 1 1a = t.arange(0, 16).view(4, 4);a tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]])123# 选取对角线上的元素index = t.LongTensor([[0,1,2,3]])a.gather(0, index) tensor([[ 0, 5, 10, 15]])123# 选取反对角线上的元素index = t.LongTensor([[3, 2, 1, 0]]).t()a.gather(1,index) tensor([[ 3], [ 6], [ 9], [12]])123# 选取反对角线上的元素，注意与上面不同index = t.LongTensor([[3, 2, 1, 0]])a.gather(0, index) tensor([[12, 9, 6, 3]])123# 选取两个对角线上的元素index = t.LongTensor([[0, 1, 2, 3], [3, 2, 1, 0]]).t()b = a.gather(1, index);b tensor([[ 0, 3], [ 5, 6], [10, 9], [15, 12]])gather的逆操作是scatter_, gather把数据从input中按index取出，而scatter_是把取出的数据再放回去。注意scatter_函数是inplace操作。 1234out = input.gather(dim, index)--&gt;近似逆操作out = Tensor()out.scatter_(dim, index) 1234# 把两个对角线元素放回到指定位置c = t.zeros(4, 4)c.scatter_(1, index, b.float()) tensor([[ 0., 0., 0., 3.], [ 0., 5., 6., 0.], [ 0., 9., 10., 0.], [12., 0., 0., 15.]])高级索引高级索引可以看成是普通索引的扩展，但是高级索引操作的结果一般不和原Tensor共享内存。 1x = t.arange(0, 27).view(3, 3, 3);x tensor([[[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8]], [[ 9, 10, 11], [12, 13, 14], [15, 16, 17]], [[18, 19, 20], [21, 22, 23], [24, 25, 26]]])1x[[1, 2], [1, 2], [2, 0]] # 元素的个数是列表的长度 元素为x[1,1,2]和x[2,2,0] tensor([14, 24])1x[[2,1,0],[0],[1]] # 元素为最长列表的长度 x[2,0,1] x[1,0,1] x[0,0,1] tensor([19, 10, 1])1x[[0,2],...] # x[0] x[2] tensor([[[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8]], [[18, 19, 20], [21, 22, 23], [24, 25, 26]]])Tensor类型默认的Tensor类型为FloatTensor，可通过t.get_default_tensor_type修改默认类型（如果默认类型为GPU tensor，在所有操作都在GPU上进行）。 HalfTensor是专门为GPU版本设计的，同样的元素个数，显存占用只有FloatTensor的一半，所以可以极大地缓解GPU显存不足的问题，但是由于HalfTensor所能表示的数值大小和精度有限，所以可能出现溢出等问题。 数据类型 CPU tensor GPU tensor 32bit浮点 torch.FloatTensor torch.cuda.FloatTensor 64bit浮点 torch.DoubleTensor torch.cuda.DoubleTensor 16半精度浮点 N/A torch.cuda.HalfTensor 8bit无符号整型（0~255） torch.ByteTensor torch.cuda.ByteTensor 8bit有符号整型（-128~127） torch.CharTensor torch.cuda.CharTensor 16bit有符号整型 torch.ShortTensor torch.cuda.ShortTensor 32bit有符号整型 torch.IntTensor torch.cuda.IntTensor 64bit有符号整型 torch.LongTensor torch.cuda.LongTensor 各数据类型之间可以互相转换，type(new_type)是通用的做法，同时还有float、long、half等快捷方法。CPU tensor与GPUtensor之间的互相装换通过tensor.cuda和tensor.cpu的方法实现。Tensor还有一个new方法，用法与t.Tensor一样，会调用该tensor对应类型的构造函数，生成与当前tensor类型一致的tensor。 123456# 设置默认tensor类型, 注意参数是字符串# t.set_default_tensor_type('torch.IntTensor') 会报错# TypeError: only floating-point types are supported as the default type# t.get_default_dtype() 返回 torch.float32# t.set_default_dtype(t.int) 报错 TypeError: only floating-point types are supported as the default type 1a = t.Tensor(2, 3);a tensor([[1.8609e+34, 1.8179e+31, 1.8524e+28], [9.6647e+35, 2.0076e+29, 7.3185e+28]])1b = a.int();b tensor([[-2147483648, -2147483648, -2147483648], [-2147483648, -2147483648, -2147483648]], dtype=torch.int32)1c = a.type_as(b);c tensor([[-2147483648, -2147483648, -2147483648], [-2147483648, -2147483648, -2147483648]], dtype=torch.int32)1d = b.new(2, 3);d tensor([[ 0, 775041082, 960062260], [1697986359, 926101553, 895706424]], dtype=torch.int32)123# 查看函数new的源码a.new?? 逐元素操作这部分操作会对tensor的每个元素进行操作，输入和输出的形状相同。 函数 功能 abs/sqrt/div/exp/fmod/log/pow.. 绝对值/平方根/除法/指数/求余/对数/求幂 cos/sin/asin/atan2/cosh 三角函数 ceil/round/floor/trunc 上取整/四舍五入/下取整/只保留整数部分 clamp(input,min,max) 超过min和max部分截断 sigmod/tanh… 激活函数 对于很多基本的运算，比如加减乘除求余等运算pytorch都实现了运算符重载，可以直接使用运算符。其中camp(x, min, max)的输出满足一个分段函数： $$y_i=\begin{cases}min, &amp; {x_i &lt; min}\\x_i, &amp; {min \leq x_i \leq max}\\max, &amp; {x_i &gt; max}\end{cases}$$ 12a = t.arange(0, 6).view(2, 3).float() # 注意要转换一下类型，否则会报错t.cos(a) tensor([[ 1.0000, 0.5403, -0.4161], [-0.9900, -0.6536, 0.2837]])1a % 3 # 等价于t.fmod(a, 5) tensor([[0., 1., 2.], [0., 1., 2.]])1a ** 2# 等价于t.power(a, 2) tensor([[ 0., 1., 4.], [ 9., 16., 25.]])1234# a中每个元素与3相比取较大的那一个print(a)t.clamp(a, min = 3) tensor([[0., 1., 2.], [3., 4., 5.]]) tensor([[3., 3., 3.], [3., 4., 5.]])归并操作这类操作会使输入形状小于输出形状，并可以沿着某一维度进行制定操作。 函数 功能 mean/sum/median/mode 均值/和/中位数/众数 norm/dist 范数/距离 std/var 标准差/方差 cumsum/cumprod 累加/累乘 几乎每个函数都有一个dim参数，用来制定在那个维度上执行。假设输入的形状是(m, n, k): 如果指定dim = 0，输出的形状为(1, n, k)或者(n, k) 如果指定dim = 1，输出的形状为(m, 1, k)或者(m, k) 如果指定dim = 2，输出的形状为(m, n, 1)或者(m, n) 也就是dim指定哪个维度，那个维度就会变成1，size中是否有1取决于keepdim，keepdim=True会保留1，keepdim默认为False。但是并非总是这样，比如cumsum。 归并运算就是对其他维度取值相同且该维度取值不同元素进行操作。 12b = t.ones(2, 3)b.sum(dim = 0, keepdim = True) tensor([[2., 2., 2.]])1b.sum(dim = 0) #keepdim = False tensor([2., 2., 2.])1b.sum(dim = 1) tensor([3., 3.])123a = t.arange(0, 6).view(2, 3)print(a)a.cumsum(dim = 1) #沿着行累加 tensor([[0, 1, 2], [3, 4, 5]]) tensor([[ 0, 1, 3], [ 3, 7, 12]])cumsum可以理解为以dim这个维度上索引取值相同的看作一个整体，比如dim=0每一行就是一个整体，cumsum运算相当于dim这个维度上取值为n的值加上取值为n-1的值（这个n-1已经进行过前面的运算，不是初始的值）。 比较比较函数有的是逐元素操作，有的是归并操作。 函数 功能 gt/lt/ge/le/eq/ne 大于/小于/大于等于/小于等于/等于/不等 topk 最大的k个数 sort 排序 max/min 比较两个tensor的最大值或最小值 表中第一行的比较操作已经重载，已经可以使用a&gt;=b, a&gt;b, a!=b和a==b，其返回结果为一个ByteTensor,可以用来选取元素(高级索引)。 max和min两个操作比较特殊，以max为例： t.max(tensor):返回tensor中最大的一个数。 t.max(tensor,dim)：指定维上最大的一个数，返回tensor和下标。 t.max(tensor1,tensor2)：比较两个tensor中较大的元素。 tensor和一个数的比较可以用clamp函数。 1a = t.linspace(0, 15, 6).view(2, 3);a tensor([[ 0., 3., 6.], [ 9., 12., 15.]])1b = t.linspace(15, 0, 6).view(2, 3);b tensor([[15., 12., 9.], [ 6., 3., 0.]])1a &gt; b tensor([[False, False, False], [ True, True, True]])1a[a &gt; b] tensor([ 9., 12., 15.])1t.max(a) tensor(15.)1t.max(a, dim = 1) torch.return_types.max( values=tensor([ 6., 15.]), indices=tensor([2, 2]))1t.max(a, b) tensor([[15., 12., 9.], [ 9., 12., 15.]])123# 比较a和10较大的元素t.clamp(a, min=10) tensor([[10., 10., 10.], [10., 12., 15.]])线性代数pytorch的线性函数封装了Blas和Lapack。 函数 功能 trace 对角线元素（矩阵的迹） diag 对角线元素 triu/tril 矩阵的上三角/下三角，可以指定偏移量 mm/bmm 矩阵乘法，batch的矩阵乘法 addmm/addbmm/addmv 矩阵运算 t 转置 dot/cross 内积/外积 inverse 求逆矩阵 svd 奇异值分解 需要注意矩阵装置会导致储存空间不连续，需调用它的.contiguous方法将其转为连续。 12b = a.t()b.is_contiguous(),b (False, tensor([[ 0., 9.], [ 3., 12.], [ 6., 15.]]))1b.contiguous() tensor([[ 0., 9.], [ 3., 12.], [ 6., 15.]])Tensor和Numpytensor和numpy数组之间具有很高的相似性，彼此之间相互操作也十分高效。需要注意，numpy和tensor共享内存。当遇到tensor不支持的操作时，可先转成Numpy数组，处理后再装回tensor，其转换开销很小。 广播法则是科学运算中经常使用的一个技巧，它在快速执行向量化的同时不会占用额外的内存、显存。Numpy的广播法则定义如下： 让所有输入数组都向shape最长的数组看齐，shape中不足的部分通过在前面加1补齐。 两个数组要么在某一个维度的长度一致，要么其中一个为1，否则不能计算。 当输入数组的某个维度的长度为1时，计算时沿着此维度复制扩充成一样的形状。 pytorch当前已经支持了自动广播法则，但建议可以手动通过函数实现广播法则，更直观不易出错。 unsqueeze或者view：为数据的某一维的形状补1，实现法则1。 expand或者expand_as，重复数组，实现法则3；该操作不会复制数组，所以不会占用额外的空间。 注意:repeat实现有expand类似，但是repeat会把相同数据复制多份，因此会占用额外空间。 12a = t.ones(3, 2)b = t.zeros(2, 3, 1) 1234567# 自动广播法则# 第一步：a是二维，b是三维，所以先在较小的a前面补1，# 即：a.unsqueeze(0), a的形状变成(1, 3, 2), b的形状是(2, 3, 1),# 第二步：a和b在第一维和第三维的形状不一样，其中一个为1# 可以利用广播法则扩展，两个形状都变成了(2, 3, 2)(a + b).shape,a + b (torch.Size([2, 3, 2]), tensor([[[1., 1.], [1., 1.], [1., 1.]], [[1., 1.], [1., 1.], [1., 1.]]]))1a.unsqueeze(0).expand(2, 3, 2) + b.expand(2, 3, 2) tensor([[[1., 1.], [1., 1.], [1., 1.]], [[1., 1.], [1., 1.], [1., 1.]]])123import numpy as npa = np.ones([2, 3], dtype = np.float32)a array([[1., 1., 1.], [1., 1., 1.]], dtype=float32)1b = t.from_numpy(a);b tensor([[1., 1., 1.], [1., 1., 1.]])12b = t.Tensor(a) # 也可以直接讲numpy对象传入Tensor，这种情况下若numpy类型不是Float32会新建。b tensor([[1., 1., 1.], [1., 1., 1.]])12c = b.numpy() # a, b, c三个对象共享内存c array([[1., 1., 1.], [1., 1., 1.]], dtype=float32)12# expand不会占用额外空间，只会在需要时才扩充，可极大地节省内存。e = t.Tensor(a).unsqueeze(0).expand(1000000000000, 2, 3) 内部结构tensor分为头信息区（Tensor）和存储区（Storage），信息区主要保存着tensor的形状（size），步长（stride）、数据类型（type）等信息，而真正的数据则保存成连续的数组。 graph LR; A[Tensor A: *size *stride * dimention...] --> C[Storage:*data *size ...]; B[Tensor B: *size *stride * dimention....] --> C[Storage:*data *size ...]; 一般来说，一个tensor有着与之对应的storage，storage是在data之上封装的接口，便于使用。不同的tensor的头信息一般不同，但却可能使用相同的storage。下面我们来看两个例子。 12a = t.arange(0, 6)a.storage() 0 1 2 3 4 5 [torch.LongStorage of size 6]12b = a.view(2, 3)b.storage() 0 1 2 3 4 5 [torch.LongStorage of size 6]123# 一个对象的id值可以看作它在内存中的地址# a和b storage的内存地址一样，即是同一个storageid(b.storage()) == id(a.storage()) True1234# a改变，b也随之改变，因为它们共享storagea[1] = 100b tensor([[ 0, 100, 2], [ 3, 4, 5]])12c = a[2:]c.storage() 0 100 2 3 4 5 [torch.LongStorage of size 6]12c.data_ptr(), a.data_ptr(), c.dtype # data_ptr返回tensor的首元素的内存地址# 可以看出相差16，这是因为2x8相差两个元素，每个元素占8个字节 (61509136, 61509120, torch.int64)12c[0] = -100 # c[0]的内存地址对应a[2]内存地址a tensor([ 0, 100, -100, 3, 4, 5])123d = t.Tensor(c.float().storage())d[0] = 6666b tensor([[ 0, 100, -100], [ 3, 4, 5]])123# 下面4个共享storageid(a.storage()) == id(b.storage()) == id(c.storage()) == id(d.storage()) True1a.storage_offset(), c.storage_offset(), a[3:].storage_offset() (0, 2, 3)12e = b[::2, ::2] # 隔2行/列取一个元素id(e.storage()) == id(a.storage()) True1b.stride(), e.stride() ((3, 1), (6, 2))1e.is_contiguous() False 可见绝大多数操作并不修改tensor的数据，只是修改头信息。这样更节省内存，同时提升了处理的速度。但是，有些操作会导致tensor不连续，这时需调用tensor.contiguous方法将他们变成连续数据，该方法复制数据到新的内存，不再与原来的数据共享storage。 另外高级索引一般不共享内存，而普通索引共享storage。 其他有关Tensor的话题持久化tensor的保存和加载十分简单，使用t.save和t.load即可完成相应功能。在save/load时可以指定使用的pickle模块，在load时还可以将GPU tensor映射到CPU或其他GPU上。 123456789if t.cuda.is_available(): a = a.cuda(1) t.save(a, 'a.pth') # 加载为b，储存于GPU1上（因为保存时就在GPU1上） b = t.load('a.pth') # 加载为c，储存在CPU c = t.load('a.pth', map_location = lambda storage,loc:storage) # 加载为d，储存于GPU0上 d = t.load('a.pth', map_location = &#123;'cuda:1':'cuda:0'&#125;) 向量化向量化计算是一种特殊的并行计算方式，通常是对不同的数据执行同样的一个或一批指令。向量化可极大第提高科学运算的效率。Python有许多操作很低效，尤其是for循环。在科学计算中要极力避免使用Python原生的for循环，尽量使用向量化的数值计算。 12345def for_loop_add(x, y): result = [] for i, j in zip(x, y): result.append(i + j) return t.Tensor(result) 12x = t.zeros(100)y = t.ones(100) 12%timeit -n 10 for_loop_add(x, y)%timeit -n 10 x + y 729 µs ± 414 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) The slowest run took 4.81 times longer than the fastest. This could mean that an intermediate result is being cached. 3.5 µs ± 2.69 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)可见有好几百倍的速度差距，因此在实际使用中应尽量调用内建函数，这些函数底层由C/C++实现，能通过执行底层优化实现高效计算。 此为还需要注意几点： 大多数t.function都有一个参数out，这时产生的结果将保存在out指定的tensor之中 t.set_num_threads可以设置pytorch进行CPU多线程并行计算时所占用的线程数，来限制pytorch所占用的CPU数目。 t.set_printoptions可以用来设置打印tensor时的数值精度和格式。 1a = t.randn(2, 3); a tensor([[-0.1227, -0.0569, -0.6876], [ 1.6025, 0.6995, 0.1694]])1t.set_printoptions(precision = 10);a tensor([[-0.1226951405, -0.0568769276, -0.6875813603], [ 1.6024936438, 0.6995284557, 0.1693879962]])]]></content>
      <categories>
        <category>笔记</category>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[thinkload]读书-疑问]]></title>
    <url>%2F2019%2F08%2F13%2Fdeeplearning-book%2F</url>
    <content type="text"><![CDATA[2019-8-13 为什么要求算法最小化cost function却要以准确率错误率来衡量它？从cost到准确率丢失了衡量差距到底有多大的信息，这两个并不等价啊！ 如何衡量一个被选择的函数在某一目的上达到了多少效果？或者起到了多少作用？ 把输入端之前看成也连接了一个网络，这个网络是一种输出数据的网络，两个网络连接在一起看成一个大网络，而这种网络的生成目的应当是不同于后面我们人类设计网络的目的。但是输出的结果仍能一定程度上的符合人类需求，是不是说网络的每个部分可以存在不同的目标？ 有一个迷宫一样的屋子，同样也是一个挑战，找出从一楼走到天台的最短路径，有一万个人来接受挑战每个走到屋顶的人都被告知自己是否是走的最短路径，每个人都是独立的，有自己的判断标准，当他再次上楼时如何分析他们行为的变化？]]></content>
      <categories>
        <category>thinkload</category>
        <category>花书</category>
      </categories>
      <tags>
        <tag>thinkload</tag>
        <tag>花书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thinkload]]></title>
    <url>%2F2019%2F08%2F10%2Fthinkload%2F</url>
    <content type="text"><![CDATA[Thinkload, download something from my mind when thinking. 2019-08-10 要达到完全的确定性，在下定义的角度必然需要无穷个修饰词, 或者说解释无穷个足够的特性，或者说无穷个参数。 另一个角度，把具有存在的物体可以看做一个函数，一个从一个定义域（一个包含所有我们在意的物体的集合）映射到一个可观测领域的函数，对于这个可观测领域的人要准确确定其存在或理解其存在需要理解这个函数的所有参数。 而因为有很多观察角度，就有很多观测领域，对于每个领域的参数又显然是不同的，对一个领域准确注定对另一不同领域就不那么准确。 也可以说函数的参数确定了可观测领域，函数的参数里蕴含了可观测领域的性质，这么看物体本身到底是什么就不那么重要，更重要的是可观测领域的性质，更重要的是观察物体的角度。 那参数是怎么得到的呢？这里发现，我们认识一个新的物体的存在必然需要一些先天的或者一些先验的存在，比如视觉听觉等五感之类的，或者一些产生在大脑的感觉，更进一步是思维灵魂的东西，或者直接说自我的存在—一个观察者自我的存在。 之前思考问题时犯了个错，不该不严谨的将物体给以“个”的量词，使得思考范围被放到离散的物体分布。 可能通过“试错”的方式学习有效，和反复试验取频率作为概率的方法有效这件事有相似性。另外，大数定律的内在含义到底是什么？为什么反复试验起作用？]]></content>
      <categories>
        <category>thinkload</category>
      </categories>
      <tags>
        <tag>thinkload</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【notes】docker学习笔记6-docker容器数据管理]]></title>
    <url>%2F2019%2F08%2F09%2Fdocker-6%2F</url>
    <content type="text"><![CDATA[docker容器的数据管理简介 docker容器的数据卷 docker的数据卷容器 docker数据卷的备份和还原 docker容器的数据卷什么是数据卷(Data Volume)docker的生存周期是与运行的程序相一致的，而我们需要数据持久化，docker容器之间也需要共享一些数据 数据卷是经过特殊设计的目录，可以绕过联合文件系统（UFS)，为一个或多个容器提供访问。 数据卷设计的目的，在于数据持久化，它完全对独立于容器的生存周期，因此docker不会在容器删除时删除其挂载的数据卷，也不会存在类似的垃圾收集机制，对容器引用的数据卷进行处理。 数据卷架构： docker数据卷独立于docker，独立运docker的生存周期。 docker数据卷位于docker的宿主机中文件系统。 docker数据卷既可以是目录也可是文件。 docker数据卷与宿主机进行数据共享。 同一目录或文件可以支持多个容器 数据卷的特点 数据卷在容器启动时初始化，如果容器使用的镜像在挂载点包含了数据，这些数据会拷贝到新初始化的数据卷中。 数据卷可以在容器之间共享和重用 可以对数据卷里的内容直接进行修改 数据卷的变化不会影响镜像的更新 卷会一直存在，即使挂载数据卷的容器已经被删除 数据卷的使用 为容器添加数据卷 1sudo docker run -v ~/container_data:/data -it ubuntu /bin/bash 在本机系统的目录:在容器中映射的目录名 注：这种方式（bind mount)已不推荐使用，应使用volume方式 123456docker volume create my_volume # 创建卷docker volume ls # 卷列表docker volume inspect my_volume #卷信息docker volume rm my_volume # 删除卷docker run -v [卷名]:[容器目录]:[选项列表] -it ubuntu /bin/bash 详情：https://deepzz.com/post/the-docker-volumes-basic.html 为数据卷添加访问权限 1sudo docker run -v [卷名]:[容器目录]:ro(访问权限) -it ubuntu /bin/bash 使用dockerfile构建包含数据卷的镜像dockerfile指令： VOLUME [“/data1”, “/data2”] 不能映射到本地目录，并且运行同一镜像的不同容器所创建的数据卷也是不一样的。 docker的数据卷容器什么是数据卷容器： 命名的容器挂载数据卷，其他容器通过挂载这个容器实现数据共享，挂载数据卷的容器，就叫做数据卷容器 图示： 挂载数据卷容器的方法 1docker run --volumes-from [CONTAINER NAME] 如果数据卷容器删除（即使同时删除挂载的数据卷）后，挂载该数据卷容器的容器的数据目录仍存在且有效。 数据卷容器的作用仅仅是将数据卷挂载的配置传递到挂载了数据卷容器的新容器中。 docker数据卷的备份与还原 数据备份方法 1docker run --volumes-from [container name] -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar [container data volume] 数据还原方法 1docker run --volumes-from [container name] -v $(pwd):/backup ubuntu tar xvf /backup/backup.tar [container data volume]]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【notes】docker学习笔记5-dockerfile]]></title>
    <url>%2F2019%2F08%2F08%2Fdocker-5%2F</url>
    <content type="text"><![CDATA[dockerfile指令指令格式注释： # Comment指令： INSTRUCTION argument FROM FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; 必须已经存在的镜像，也就是基础镜像 必须是第一条非注释指令 MAINTAINER MAINTAINER &lt;name&gt; 指定镜像的作者信息，包含镜像的所有者和练习方式 RUN构建构成运行的 RUN &lt;command&gt; (shell模式) /bin/sh -c command RUN [“executable”, “param1”, “param2”] (exec模式) RUN[“/bin/bash”, “-c”, “echo hello”] EXPOSE EXPOSE &lt;port&gt; [&lt;port&gt;…] 指定运行该镜像的容器使用的端口，但只是告诉docker会使用特定的端口号，出于安全考虑不会自动打开，在容器运行时仍需要手动指定端口映射。CMD ENTRYPOINT 指定容器启动时运行的命令 CMD [“executable”, “param1”, “param2”] (exec模式) CMD command param1 param2 (shell模式) CMD [“params1”, “params2”] (作为ENTRYPOINT指令的默认参数) 在docker run时如果指定命令的话dockerfile里的cmd命令会被覆盖掉。 ENTRYPOINT [“executable”, “param1”, “param2”] (exec模式) ENTRYPOINT command param1 param2 (shell模式) 默认不会被覆盖，如果需要覆盖需要指定docker run –entrypoint 覆盖 ADD COPY VOLUME设置镜像的目录和文件 ADD &lt;src&gt;…&lt;dest&gt; ADD [“&lt;src”…”“] (适用于文件路径中有空格) COPY &lt;src&gt;…&lt;dest&gt; COPY [“&lt;src”…”“] (适用于文件路径中有空格) 可以使文件地址（构建目录的相对地址），也可以是远程url（推荐使用curl获取文件内容） ADD vs. COPY ADD包含类似tar的解压功能 如果单纯复制文件，docker推荐使用COPY VOLUME [“/data”] 添加卷 WORKDIR ENV USER构建及容器运行时的环境设置 WORKDIR /path/to/workdir (设置工作目录，通常使用绝对路径，否则会一直传递下去) e.g: 1234WORKDIR /aWORKDIR bWORKDIR CRUN pwd # 结果为 /a/b/c ENV &lt;key&gt;&lt;value&gt; ENV &lt;key&gt;=&lt;value&gt; 设置环境变量 USER daemon USER user USER uidUSER user:group USER uid:gidUSER user:gid USER uid:group 指定运行的用户，若不指定则默认root用户。 ONBUILD ONBUILD [INSTRUCTION] 镜像触发器 当一个镜像被其他镜像作为基础镜像时执行 会在构建过程中插入指令 dockerfile构建过程 从基础镜像运行一个容器 执行一条指令，对容器作出修改 执行类似docker commit的操作， 提交一个新的镜像层（中间层镜像） 再基于刚提交的镜像运行一个新的容器 执行dockerfile中的下一条指令，直至所有指令执行完毕 中间层镜像进行调试 注：dockerfile会删除中间层镜像容器但不会删除中间层镜像 构建缓存，构建时会建立缓存，因此第二次执行构建命令会很快，是因为使用了缓存。 不使用缓存 1docker build --no-cache 另一种方法通过更改缓存刷新时间 FROM Ubuntu:14:04MAINTAINER dormancypress user@mail.comENV REFRESH_DATE 2019-08-08RUN apt-get updateRUN apt-get install -y nginxEXPOSE 80 修改REFRESH_DATE时间 查看镜像构建过程 1docker history [image]]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【notes】docker学习笔记4-docker客户端与守护进程]]></title>
    <url>%2F2019%2F08%2F07%2Fdocker-4%2F</url>
    <content type="text"><![CDATA[docker的C/S模式 客户端与守护进程通信的接口 命令行接口 remote API： RESTful风格API STDIN STDOUT STDERR 语言参考：https://docs.docker.com/reference/api/docker_remote_api 连接方式 unix:///var/run/docker.sock 默认方式 tcp://host:port fd://socketfd 利用socket进行通信 查看正在运行的守护进程 1ps -ef | grep docker 连接socket进行通信 12nc -U /var/run/docker.sockGET /info HTTP/1.1 以上都是在本地的访问，docker也支持远程访问。 docker守护进程的配置和操作 查看守护进程 12ps -ef | grep dockersudo status docker 守护进程的启动、停止和重启 123sudo service docker startsudo service docker stopsudo service docker restart docker的启动选项 1docker -d [OPTIONS] #所以守护形式运行 运行相关: -D, –debug = false -e, –exec-driver = “native” -g, –graph = “/var/lib/docker” –icc = true -l, –log-level = “info” –label = [] -p, –pidfile = “/var/run/docker.pid” docker服务器连接相关： -G, –group = “docker” -H, –host = [] –tls = false –tlscacert = “/home/sven/.docker/ca.pem” –tlscert = “/home/sven/.docker/cert.pem” –tlskey = “/home/sven/.docker/key.pem” –tlsverify = false RemotAPI相关： –api-enable-cors = false Registry相关： –insecure-registry = [] –registry-mirror = [] 网络设置相关： -b, –bridge = “” –bip = “” –fixed-cidr = “” –fixed-cidr-v6 = “” –dns = [] –dns-search = [] –ip = 0.0.0.0 –ip-forward = true –ip-masq = true –iptables = true –ipv6 = false –mtu = 0 启动配置文件 /etc/default/docker 注：ubuntu 16.04及以上版本使用： 修改/lib/systemd/system/docker.service中的ExecStart 加载配置： 123systemctl daemon-reloadservice docker restartdocker info docker的远程访问 第二台安装docker的服务器 保证Client API与Server API版本一致 修改docker守护进程启动选项 修改服务器端配置 -H tcp://host:post unix:///path/to/socket fd://* or fd//socketfd 守护进程默认配置： -H unix:///var/run/docker.sock 注：我的默认的是 fd:// 改为 tcp: tcp://0.0.0.0:2375 1curl http://ip:2375/info 修改客户端配置 -H tcp://host:post unix:///path/to/socket fd://* or fd//socketfd 默认配置： -H unix:///var/run/docker.sock docker -H tcp//ip:2375 # 太麻烦 export DOCKET_HOST=”tcp://ip:2357” # 使用环境变量 export DOCKET_HOST=”tcp://ip:2357” # 使用本地 怎样在设置了远程连接的服务器也支持本机连接？答：给-H再增加一个方式，-H可以设置多个值。]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【notes】docker学习笔记3-docker镜像]]></title>
    <url>%2F2019%2F08%2F06%2Fdocker-3%2F</url>
    <content type="text"><![CDATA[查看和删除镜像 镜像的存储位置：/var/lib/docker 列出镜像1docker images [OPSIONS] [REPOSITORY] -a, –all = false # 显示所有镜像，默认并不显示中间层镜像（没有标签名的镜像） -f, –filter = [] # 过滤条件 –no-trunc = false # 不使用截断的形式来显示数据(默认使用截断显示EID，比文件名短) -q, –quiet = false # 只显示EID 镜像标签和仓库 镜像仓库 区分： REPOSITORY 仓库 REGISTRY 仓库 REGISTRY里会有很多REPOSITORY仓库，每个REPOSITORY里会有一个个独立的镜像。 标签 TAG 镜像的名字 = 镜像仓库名 : 镜像标签 –对应–&gt; 镜像ID ubuntu:latest, ubuntu:14.04, ….. 如果没有指定标签，默认为latest。 同一仓库的不同标签可以对应同一镜像ID，也就是说可以根据需求给同一镜像文件打上不同的标签。 没有标签名的镜像称作中间层镜像。 查看镜像1docker inspect [OPTIONS] CONTIANER|IMAGE [CONTAINER|IMAGE...] -f, –format=”” 删除镜像1docker rmi [OPTIONS] IMAGE [IMAGE...] -f, –force = false 强制删除 –no-prune = false 不删除未打标签的父镜像 对应多个标签的镜像文件可以直接用ID选定所有标签 1docker rmi ID 获取和推送镜像查找镜像 Docker Hub https://registry.hub.docker.com docker search 1docker search [OPTIONS] TERM –automated = false –no-trunc = false -s, stars = 0 只显示最少多少stars的 最多返回25个结果 拉取镜像1docker pull [OPTIONS] NAME [:TAG] -a, –all-tags = false 下载仓库中所有被标记的镜像 推送镜像1docker push username/IMAGE 构建镜像 保存对容器的修改，并再次使用 自定义镜像的能力 以软件的形式打包并分发服务及其运行环境 docker commit通过容器构建 1docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] -a, –author=”” Author e.g., “John Hannibal Smith hannibal@a-team.com“ -m, –message=”” 记录构建的信息 -p, –pause = true 不暂停容器的运行 docker build通过Dockerfile文件构建 dockerfile: #First DockerfileFROM ubuntu:14.04MAINTAINER dormancypress “dormancypress@outlook.comRUN apt-get updateRUN apt-get install -y nginxEXPOSE 80 1docker build [OPTIONS] PATH|URL|- –force-rm = false –no-cache = false –pull=false -q,–quiet = false –rm = true -t, –tag=””]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【notes】docker学习笔记2-docker容器]]></title>
    <url>%2F2019%2F08%2F06%2Fdocker-2%2F</url>
    <content type="text"><![CDATA[容器的基本操作启动容器 仅一次命令 1docker run IMAGE [COMMAND] [ARG] 启动交互式容器 1docker run -i -t IMAGE /bin/bash -i –interactive=ture | false 默认是false，为容器始终打开标准输入-t –tty=true | false 默认是false，分配一个终端 自定义容器名字 1docker run --name=自定义名 -i -t IMAGE /bin/bash 重新启动已建立的容器docker start [-i] 容器名 查看容器 不加参数是正在运行的容器，-a是所有容器，-l是最新创建的一个容器。 1docker ps [-a] [-l] 查看容器参数 1docker inspect [ID] or [name] 删除容器1docker rm 容器名 守护式容器什么是守护式容器： 能够长期运行 没有交互式会话 以守护形式运行容器：12docker run -i -t IMAGE /bin/bashCtrl + P Ctrl + Q 附加到运行中的容器1docker attach 容器名 启动守护式容器1docker run -d 镜像名 [COMMAND] [ARG...] 得知容器运行情况1docker logs [-f] [-t] [--tail] 容器名 -f –follows=true | false 默认为false 一直跟踪日志变化并返回结果-t –timestamps=true | false 默认为false 结果加上时间戳–tail= “all” 多少数量的日志 查看运行中容器进程1docker top 容器名 在运行中的容器内启动新进程1docker exec [-d] [-i] [-t] 容器名 [COMMAND] [ARG...] 停止守护式容器 发送指令等待停止 1docker stop 容器名 直接停止容器 1docker kill 容器名 ###在容器中部署静态网站 设置容器的端口映射run [-P] -P , –publish-all = true | false 默认为false 为容器暴露的所有端口设置映射 1docker run -P -t -i ubuntu /bin/bash -p , 指定端口 容器端口 1docker run -p 80 -i -t ubuntu /bin/bash 宿主机端口:容器端口 1docker run -p 8080:80 -i -t ubuntu /bin/bash ip::容器端口 1docker run -p 0.0.0.0:80 -i -t ubuntu /bin/bash ip:宿主机端口:容器端口 1docker run -p 0.0.0.0:8080:80 -i -t ubuntu /bin/bash Nginx部署 创建映射80端口的交互式容器 1docker run -p 80 --name web -it ubuntu /bin/bash 安装Nginx 安装文本编辑器vim 1234apt-get updateapt-get upgradeapt-get install nginx -yapt-get install vim -y 创建静态页面 12mkdir -p /var/www/htmlvim index.html 修改Nginx配置文件 1vim /etc/nginx/sites-enabled/default 运行Nginx 123nginxps -efCtrl P Ctrl Q 验证网站访问 1234docker port web # 查看端口映射情况docker top web # 查看进程运行情况docker inspect web #查看ipcurl http://172.17.0.2]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【notes】docker学习笔记1-docker基本组成]]></title>
    <url>%2F2019%2F08%2F06%2Fdocker-1%2F</url>
    <content type="text"><![CDATA[Docker的基本组成 Docker Client 客户端 Docker Daemon 守护进程 Docker Image 镜像 Docker Container 容器 Docker Registry 仓库 Docker客户端/守护进程 C/S架构 docker客户端对服务器的访问： 本地/远程 docker客户端向发送给守护进程请求，守护进程的执行结果还会传回给客户端。 Docker Image镜像 构建和打包阶段。 容器的基石，相当于保存了容器运行需要的源代码。 层叠的层叠文件系统。 bootfs（引导文件系统）-&gt; rootfs(Ubuntu) -&gt; add emacs -&gt; add Apache 联合加载（union mount）:一次加载多个文件系统（add Apache，add emacs），将所有文件系统叠加在一切。镜像可以叠加在一起，位于底部的成为基础镜像（rootfs），add emacs（副镜像）。 Docker Container容器 通过镜像启动。 启动执行阶段。 配置数据和镜像层（bootfs -&gt; ······ -&gt; add emacs) -&gt; 可写层。 写时复制：docker出现变化时都会应用到可写层，先从只读镜像层复制到可写层然后只读层的文件被隐藏。 Docker Registry仓库 保存docker镜像。 分为公有和私有。公有：Docker Hub 图示结构Docker: Docker Image: Docker Container: docker基本指令 查找镜像 1docker search tutorial 下载镜像 1docker pull learn/tutorial 启动一个容器，使用echo命令输出hello world 1docker run learn/tutorial echo 'hello world' 启动一个容器下载ping 1docker run learn/tutorial apt-get install -y ping 查看有哪些容器 1docker ps -l 提交容器，即创建一个新的镜像 1docker commit [docker ID] learn/ping 用新镜像建立一个容器 1docker run learn/ping ping www.baidu.com 查看容器信息 1docker inspect [docker ID] 查看有哪些镜像 1docker image 将镜像保存到docker hub上 1docker push /learn/ping Docker容器相关技术简介Docker依赖的Linux内核特性 Namespaces 命名空间 提供了系统资源的隔离，for轻量级虚拟化服务 五种命名空间： PID 进程隔离 NET 管理网络接口 IPC 管理跨进程通信的访问 MNT 管理挂载点 UTS 隔离内核和版本标识 Control groups 控制组 资源限制（内存上限等） 优先级设定（设定哪些进程组使用哪些资源） 资源计量 资源控制（挂起恢复） Docker容器的能力 文件系统隔离：每个容器都有自己的root文件系统 进程隔离： 每个容器都运行在自己的进程环境中 网络隔离： 容器间的虚拟网络接口和IP地址都是分开的 资源隔离和分组：使用cgroups将CPU和内存之类的资源独立分配给每个Docker容器]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Xshell管理虚拟机Ubuntu]]></title>
    <url>%2F2019%2F08%2F03%2Fxshell-vmware%2F</url>
    <content type="text"><![CDATA[因为使用VM虚拟机太过占用资源，所以我们可以用Xshell连接到虚拟机，来达到节省本机资源的目的。 安装SSH： 123sudo apt-get install openssh-serverservice iptables stop #关闭防火墙service ssh start #开启ssh服务 获得登录需要的ip ,在虚拟机输入： 1ifconfig ens*后面的inet后面的值就是ip。 按照我之前写过的xshell连接的教程 windows系统：Xshell下载安装+连接服务器 建立会话就ok，主机就是刚才你获得的ip，登录用的用户名和密码就是你安装时填的用户名(非root账户)和密码。 之后只需要打开虚拟机后最小化界面，从xshell登入后reboot一下虚拟机，这样从内存角度就能节省将近90多MB。 注意： reboot后就不要在打开VMware了，一直让它最小化直到关闭。]]></content>
      <categories>
        <category>Xshell</category>
      </categories>
      <tags>
        <tag>Xshell</tag>
        <tag>虚拟机</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[photoshop cc 2019安装破解]]></title>
    <url>%2F2019%2F08%2F02%2Fphotoshop-cc-2019-download%2F</url>
    <content type="text"><![CDATA[Photoshop如今已经非常常用的处理图片的软件，本文就是介绍一下photoshop cc 2019安装破解的完整过程。 注：本文参考了http://www.3322.cc/soft/48343.html 下载creative cloud什么是creative cloud？creative cloud相当于adobe系列的一个应用商城，我们可以在里面安装各种adobe系列的软件。下载链接： 官网链接 网盘链接 下载完成直接按提示安装，然后注册adobe账号并登陆。 下载安装photoshop-cc-2019默认的下载位置在c盘，如果想改到其他盘可以点击右上角的三个点，出来菜单再点首选项。 然后点击creative Cloud界面，在安装位置条目处更改到你想安装到的位置。 打开creative cloud，找到photoshop的条目点击试用，photoshop自动下载安装成功。 利用补丁破解安装完成后安全起见先不要打开ps，我们先下载补丁工具。下载链接：网盘链接 其他链接 将压缩包里的adobe.photoshop.cc.2019.20.0.0-patch.exe文件解压到ps安装目录下，就是你刚才修改的安装位置，保证那个位置下有photoshop.exe文件。 然后点击运行补丁（你可能会听到一段诡异的音乐。。。）。 点击应用，等待出现文件补丁已成功完成的提示。 这样就破解完成了，这时再打开ps发现没有试用还有多少天的提醒了。 按照补丁制作者的建议，在 编辑 ==&gt; 首选项 ==&gt; 常规 ==&gt; 停用”主页”屏幕 打钩。 最后做好重启一下ps再试用。 注：这篇文章是我安装后就写了，我在安装完的七天后再次检验是否失效，如果失效我会更新补丁，如果补丁失效可以回来看我是否有更新方法。]]></content>
      <categories>
        <category>photoshop</category>
      </categories>
      <tags>
        <tag>破解</tag>
        <tag>photoshop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xshell：在本地浏览器使用服务器的jupyter notebook]]></title>
    <url>%2F2019%2F08%2F02%2Fhexo-jupyter%2F</url>
    <content type="text"><![CDATA[有的服务器里只是命令行，无法可视化，可能就无法使用jupyter notebook。其实需要稍微修改一下连接的属性就能在本地浏览器里打开在服务器里启动的jupyter notebook，具体操作如下： 首先右击会话管理器里的服务器标签，在菜单点击属性。 然后点击左侧的隧道，然后再点击添加。 输入两个端口号，我这输入的是jupyter notebook默认的8888端口，然后点确定 然后再取消右下方转发X11连接到的选项，然后点确定。 之后双击会话管理器里的服务器进行连接，在命令行里输入jupyter notebook，启动后在浏览器里访问就会看到jupyter notebook的界面了。]]></content>
      <categories>
        <category>Xshell</category>
      </categories>
      <tags>
        <tag>Xshell</tag>
        <tag>jupyter notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows系统：Xshell下载安装+连接服务器]]></title>
    <url>%2F2019%2F08%2F01%2FXshellDownload%2F</url>
    <content type="text"><![CDATA[学习深度学习需要足够的计算资源，往往需要连接远程服务器用来计算。本篇文章就介绍一下如何在windows系统里利用xshell连接服务器。 xshell下载安装首先要下载安装包:百度网盘资源。当然也可以去官网下载安装包，选择家庭学校免费版，下载前要填一下姓名邮箱，提交后你会收到带有下载链接的邮件。 点击安装包，然后一路默认下一步就ok。如果不想安装在c盘也可以，在其他盘里专门存xshell的各种文件，安装过程中只需把主文件夹换成你刚才的文件夹就ok。 建立连接 打开xshell后，点击左上角的文件然后点新建。 然后填入服务器名称、主机、端口号,然后点确定。 双击左侧会话管理器里刚建的服务器，在弹出的窗口里填入登录用的用户名，选上记住用户名。 然后输入密码，并选上记住密码。 点击确定以后就能在黑色的shell看到已经登录成功的提示了，然后就可以在shell里进行操作了。 之后登录只需要双击左侧会话管理器里的对应标签即可。 上传下载文件 在Linux主机上，安装上传下载工具包rz及sz，使用sudo apt install lrzsz 进行安装。 从Windows上传文件，上传命令为rz；输入命令后会弹出选择要上传的本地文件的窗口。 从Linux主机下载文件，下载命令为sz ，后面跟要下载的文件名。例如： sz helloworld.py。 然后就会弹出选择要保存到本机位置的窗口。 xshell的基本操作就说这些了，这些的操作已经基本够用了]]></content>
      <categories>
        <category>Xshell</category>
      </categories>
      <tags>
        <tag>Xshell</tag>
        <tag>linux服务器</tag>
        <tag>windows</tag>
      </tags>
  </entry>
</search>
